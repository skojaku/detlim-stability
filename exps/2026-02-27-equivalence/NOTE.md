# Note

The log-likelihood of the stochastic block model and spectral decomposition of the adjacency matrix are related. Specifically, the spectral decomposition of the adjacency matrix gives us a vector that is parallel to the best node assignment in terms of the log-likelihood of the stochastic block model, up to the constraint that the network has two communities, and they have exactly the same size. 

## Setup

Consider a graph on $n$ nodes generated by a symmetric two-block stochastic block model:

- Community assignments: $s_i \in \{-1, +1\}$
- Edge probability within communities: $p$
- Edge probability between communities: $q$
- Adjacency matrix: $A$, where $A_{ij} \in \{0,1\}$ and $A_{ii} = 0$

The edge probabilities are:

$$P(A_{ij} = 1 \mid s_i, s_j) = \begin{cases} p & \text{if } s_i = s_j \\ q & \text{if } s_i \neq s_j \end{cases}$$

## Equivalence 

Edges are independent conditioned on $\mathbf{s}$:

$$\log P(A \mid \mathbf{s}) = \sum_{i < j} \left[ A_{ij} \log P_{ij} + (1 - A_{ij}) \log(1 - P_{ij}) \right]$$

where $P_{ij} = p$ if $s_i = s_j$ and $P_{ij} = q$ otherwise.

Observe that:

$$s_i = s_j \iff \frac{1 + s_i s_j}{2} = 1, \qquad s_i \neq s_j \iff \frac{1 - s_i s_j}{2} = 1$$

So we can write:

$$\log P_{ij} = \frac{1 + s_i s_j}{2} \log p + \frac{1 - s_i s_j}{2} \log q$$

$$\log(1 - P_{ij}) = \frac{1 + s_i s_j}{2} \log(1 - p) + \frac{1 - s_i s_j}{2} \log(1 - q)$$

Substituting into the log-likelihood and expanding, each $(i,j)$ term becomes:

$$A_{ij}\left[\frac{1+s_is_j}{2}\log p + \frac{1-s_is_j}{2}\log q\right] + (1-A_{ij})\left[\frac{1+s_is_j}{2}\log(1-p) + \frac{1-s_is_j}{2}\log(1-q)\right]$$

Group into parts constant in $s_is_j$ and parts linear in $s_is_j$:

$$= A_{ij}\left[\frac{\log p + \log q}{2} + s_is_j\frac{\log p - \log q}{2}\right] + (1-A_{ij})\left[\frac{\log(1-p)+\log(1-q)}{2} + s_is_j\frac{\log(1-p)-\log(1-q)}{2}\right]$$

Collecting only the terms that depend on $s_is_j$:

$$\frac{s_is_j}{2}\left[A_{ij}\bigl(\log p - \log q\bigr) + (1-A_{ij})\bigl(\log(1-p) - \log(1-q)\bigr)\right]$$

Define the constants:

$$\alpha \;=\; \log\frac{p}{q} + \log\frac{1-q}{1-p} \;=\; \log\frac{p(1-q)}{q(1-p)}, \qquad \beta \;=\; \log\frac{1-p}{1-q}$$

Then the $s_is_j$-dependent contribution per pair is:

$$\frac{s_is_j}{2}\left[\alpha A_{ij} + \beta\right]$$

Summing over all pairs:

$$ \log P(A \mid \mathbf{s} ) = C + \frac{1}{2} \sum_{ i < j } s_i s_j \left[\alpha A_{ij} + \beta\right] $$

where $C$ collects all terms independent of $\mathbf{s}$. In matrix notation:

$$\log P(A\mid\mathbf{s}) = C + \frac{\alpha}{4}\mathbf{s}^T A\mathbf{s} + \frac{\beta}{4}\mathbf{s}^T J\mathbf{s}$$

where $J = \mathbf{1}\mathbf{1}^T - I$ (all-ones matrix minus identity, since we sum over $i \neq j$). Note $\mathbf{s}^T J\mathbf{s} = (\mathbf{1}^T\mathbf{s})^2 - n$.

So the MLE problem is:

$$\hat{\mathbf{s}} = \arg\max_{\mathbf{s}\in\{-1,+1\}^n}\left[\alpha\mathbf{s}^T A\mathbf{s} + \beta(\mathbf{1}^T\mathbf{s})^2\right]$$

If we impose balanced communities, $\sum_i s_i = 0$, i.e., $\mathbf{s} \perp \mathbf{1}$. Then:

$$(\mathbf{1}^T\mathbf{s})^2 = 0$$

and the MLE reduces to:

$$\hat{\mathbf{s}} = \arg\max_{\substack{\mathbf{s}\in\{-1,+1\}^n \\ \mathbf{s}\perp\mathbf{1}}} \;\mathbf{s}^T A\mathbf{s}$$

The discrete optimization over $\{-1,+1\}^n$ is NP-hard (equivalent to MAX-CUT). Relax:

$$\{-1,+1\}^n \;\longrightarrow\; \{\mathbf{x}\in\mathbb{R}^n : \|\mathbf{x}\|^2 = n\}$$

The relaxed problem is:

$$\max_{\substack{\mathbf{x}\in\mathbb{R}^n \\ \|\mathbf{x}\|^2 = n \\ \mathbf{x}\perp\mathbf{1}}} \mathbf{x}^T A\mathbf{x}$$

By the Rayleigh-Ritz theorem, the solution is:

$$\mathbf{x}^* = \sqrt{n} \mathbf{v}_2$$

where $\mathbf{v}_2$ is the eigenvector of $A$ corresponding to the largest eigenvalue in the subspace orthogonal to $\mathbf{1}$.

In a dense planted SBM, the leading eigenvector of $A$ is approximately $\mathbf{1}/\sqrt{n}$ (corresponding to the mean degree). Therefore $\mathbf{v}_2$ is the **second eigenvector** of $A$, and the community assignment is recovered by:

$$\hat{s}_i = \text{sign}(v_{2,i})$$
